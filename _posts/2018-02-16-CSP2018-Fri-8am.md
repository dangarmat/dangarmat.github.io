---
layout: post
title: ASA Conference on Statistical Practice 2018, Friday 1 of 6, Keynote Address & Working with Messy Data
category: [R, ASA, CSP2018]
tags: [R, ASA, CSP2018]
---

![All lines](/images/smokelines01.png "All data to be clustered")

Highlights from [Conference on Statistical Practice](https://ww2.amstat.org/meetings/csp/2018/index.cfm) sessions. To keep it simple just a few notes and my favorite slide per session I attended. I work in Population Health Analytics at Legacy Hospital System in Portland, Oregon, so some of these presenters' work may be interpreted in terms of that lens.

Posts by time period:

**Friday 2/16/2018**
* **8:00 AM Keynote Address & 9:15 AM Working with Messy Data**
* [11:00 AM Streamlining Your Work Using (Shiny) Apps](https://dgarmat.github.io/CSP2018-Fri-11am/)
* [2:00 PM Data Mining Algorithms / Presenting and Storytelling](https://dgarmat.github.io/CSP2018-Fri-2pm/)
* [3:45 PM Working with Health Care Data](https://dgarmat.github.io/CSP2018-Fri-345pm/)
* [Posters I Wish I'd Seen](https://dgarmat.github.io/CSP2018-Fri-Additional-Posters/)
* [Additional Sessions I Wish I'd Attended](https://dgarmat.github.io/CSP2018-Fri-Additional/)

**Saturday 2/17/2018**
* [9:15 AM Poster Session 3 / Survival Analysis v. 'Survival' Analysis](https://dgarmat.github.io/CSP2018-Sat-915am/)
* [11:00 AM Causal Inference](https://dgarmat.github.io/CSP2018-Sat-11am/)
* [2:00 PM Deploying Quantitative Models as 'Visuals' in Popular Data Visualization Platforms](https://dgarmat.github.io/CSP2018-Sat-2pm/)
* [Additional Sessions I Wish I'd Attended](https://dgarmat.github.io/CSP2018-Sat-Additional/)

## Friday 2/16/2018

## 8:00 AM Keynote Address

### Reflections on Career Opportunities and Leadership in Statistics, *Lisa LaVange, The University of North Carolina*

Leadership - to some extent just do it - statistical training alone provides perspective and a right to contribute. There are "statistical leadership" opportunities and I felt inspired to improve art of of contributing.

Precision medicine is determining the right intervention at right time at the right dose. It struck me care management is precision medicine, or could become it.

## 9:15 AM Working with Messy Data 

### Practical Time-Series Clustering for Messy Data in R *[Jonathan Robert Page](http://www2.hawaii.edu/~jrpage/), University of Hawaii Economic Research Organization*

Problem: a Kenyan GoFundMe type site wants to know if there are clusters of projects in terms of funding patterns to get a sense which need promotion and which do not.

He took time series data on donations to projects and looked for clusterings using two methods: Dynamic Time Warping (DTW) using [dtwclust R package](https://cran.r-project.org/web/packages/dtwclust/index.html) and k-Shapes. He uses cumulative sums, not daily donation amounts as the y-value.

After cleaning (for which he presents [a wealth of R code](https://github.com/jonpage/csp2018)) it feels easy (maybe he makes it look easy). DTW seems to cluster on when changes occur, so assumes similar changes and measures time distance, x-distance between the key changes, whereas k-shape seems to measure vertical distance at the same time - but not sure these are correct interpretations. 

He likes to present clusters of Time Series in x by x style - so 4, 9, or 16 clusters. He does this to show stakeholders different resolutions / zoom levels. 

![Clusters of donations with k = 9 k-Shapes](/images/smokelines.png "Clusters of donations with k = 9 k-Shapes")

Pretty "smoke graph" I'd call it, with alpha = 0.1. Blue line is medoid of normalized cluster. Can see in the second one a cluster where no one ever donates anything in the first 30 days. Or Cluster 5, does great at first then flattens out. Clusters 8 and 9 look the most promising - since they finish their first 30 days still with an upward slope, that may indicate continuing interest.

### 	Doing Data Linkage: A Behind-the-Scenes Look *[Clinton J. Thompson](https://www.researchgate.net/profile/Clinton_Thompson), National Center for Health Statistics, CDC*

Problem: full story of health and death is in two datasets, which require being linked, but these files have millions of rows and no common ID, and thus trillions of possible combinations, so linkage isn't straightforward. The QC process takes a long time.

Data linkage processes can be challenging and it is possible to enhance review and quality control processes. For these two data sets, they link on birth year, sex and first name. Interestingly first name is a function of birth year and sex, so they eventually decide to aggregate it to just first initial. They found this aggregation method was necessary for working with relatively big data without proper tools to handle it, but ended up disguising issues at a more granular level. 

One big change for the most recent run of this linkage in 2015 was to make the upper cutoff of birth year higher at 1990+ instead of 1965+. So everyone who was born after that year in both data sets is in one categorical group. They had to investigate how this affected the quality of the linking, and these sets of box plots with year on the y-axis and weight on the x-axis show how much the distribution changed by this choice of feature engineering. Each point is a different first name. Can see this is one tab "FName by DOB Year" of their QA data visualization dashboard. 

![Boxplots of weight of age variable](/images/boxplots01.png "Boxplots showing how weights changed")

With further comparisons of 2011 vs. 2015 distributions and summary statistics, they ultimately concluded the change was necessary to maintain the quality of past data linkages.

He uses dashboards to QC. I see this being a useful way to monitor data for possible errors - a dashboard designed for the analytics team that attempts to answer the question "can I trust this new data?" Could program in checks for the kinds of messes we've seen before, and maybe even do processing in PowerBI with check boxes to make suggested corrections. Maybe a top 5 correction suggestions, and check yes to fix it in the output file.

Up next: [11:00 AM Streamlining Your Work Using (Shiny) Apps](https://dgarmat.github.io/CSP2018-Fri-11am/)

