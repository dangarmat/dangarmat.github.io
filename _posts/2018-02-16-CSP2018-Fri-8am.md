---
layout: post
title: ASA Conference on Statistical Practice 2018 Friday, Keynote Address & Working with Messy Data
category: [R, ASA, CSP2018]
tags: [R, ASA, CSP2018]
---

![CSP Conf Logo](/images/csp2018.png "Conference Logo")

Highlights from [Conference on Statistical Practice](https://ww2.amstat.org/meetings/csp/2018/index.cfm) sessions. To keep it simple just a few notes and my favorite slide per session I attended. I work in Population Health Analytics at Legacy Hospital System in Portland, Oregon, so some of these presenters' work may be interpritted in terms of that lense.

Posts by time period:

**Friday 2/16/2018**
* **8:00 AM Keynote Address & 9:15 AM Working with Messy Data**
* [11:00 AM Streamlining Your Work Using (Shiny) Apps](2018-02-16-CSP2018-Fri-11am.md)
* [2:00 PM Data Mining Algorithms / Presenting and Storytelling](2018-02-16-CSP2018-Fri-2pm.md)
* [3:45 PM Working with Health Care Data](2018-02-16-CSP2018-Fri-345pm.md)

**Saturday 2/17/2018**
* [9:15 AM Poster Session 3 / Survival Analysis v. 'Survival' Analysis](2018-02-17-CSP2018-Sat-915am.md)
* [11:00 AM Causal Inference](2018-02-17-CSP2018-Sat-11am.md)
* [2:00 PM Deploying Quantitative Models as 'Visuals' in Popular Data Visualization Platforms](2018-02-17-CSP2018-Sat-2pm.md)
* [Additional Sessions I Wish I'd Attended](2018-02-17-CSP2018-Fri-Additional.md)

## Friday 2/16/2018

## 8:00 AM Keynote Address

### Reflections on Career Opportunities and Leadership in Statistics, *Lisa LaVange, The University of North Carolina*

Leadership - to some extent just do it - statistical training alone provides perspective and a right to contribute. There are "statistical leadership" opportunities and I felt inspired to improve art of of contributing.

Precision medicine is determining the right intervention at right time at the right dose. It struck me care management is precision medecine, or could become it.

## 9:15 AM Working with Messy Data 

### Practical Time-Series Clustering for Messy Data in R *[Jonathan Robert Page](http://www2.hawaii.edu/~jrpage/), University of Hawaii Economic Research Organization*

Problem: a Kenyan GoFundMe type site wants to know if there are clusters of projects in terms of funding patterns to get a sense which need promotion and which do not.

He took time series data on donations to projects and looked for clusterings using two methods: Dynamic Time Warping (DTW) using [dtwclust R package](https://cran.r-project.org/web/packages/dtwclust/index.html) and k-Shapes. He uses cumulative sums, not daily donation amounts as the y-value.

After cleaning (for which he presents [a wealth of R code](https://github.com/jonpage/csp2018)) it feels easy (maybe he makes it look easy). DTW seems to cluster on when changes occur, so assumes similar changes and measures time distance, x-distance between the key changes, whereas k-shape seems to measure vertical distance at the same time - but not sure these are correct interpritations. 

He likes to present clusters of Time Series in x by x style - so 4, 9, or 16 clusters. He does this to show stakeholders different resolutions / zoom levels. 

![Clusters of donations with k = 9 k-Shapes](/images/smokelines.png "Clusters of donations with k = 9 k-Shapes")

Pretty "smoke graph" I'd call it, with alpha = 0.1. Blue line is medoid of normalized cluster. Can see in the second one a cluster where no one ever donates anything in the first 30 days. Or Cluster 5, does great at first then flattens out. Clusters 8 and 9 look the most promising - since they finish their first 30 days still with an upward slope, that may indicate continuing interest.

### 	Doing Data Linkage: A Behind-the-Scenes Look *[Clinton J. Thompson](https://www.researchgate.net/profile/Clinton_Thompson), National Center for Health Statistics, CDC*

Problem: full story of health and death is in two datasets, which require being linked, but these files have millions of rows and no common ID, and thus trillions of possible combinations, so linkage isn't straightforward. 

Data linkage processes can enhance review and quality control process. He uses dashboards to QC. I see this being a useful way to monitor data for possible errors - a dashboard designed for the analytics team that attempts to answer the question "can I trust the new data?" Could program in checks for the kinds of messes we've seen before, and maybe even do processing in PowerBI with check boxes to make suggested corrections. Maybe a top 5 correction suggestions, and check yes to fix it in the output file.

Upo next: 11:00 AM Streamlining Your Work Using Apps

